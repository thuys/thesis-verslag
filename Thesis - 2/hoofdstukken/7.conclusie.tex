\chapter{Conclusie}\label{sec:conclusie}
Deze thesis heeft de kloof verkleint tussen de informatie die nodig en beschikbaar is voor het selecteren van een DBMS. Dit is gebeurd door het ontwikkelen een nieuwe benchmarking tool om consistentie- en beschikbaarheidseigenschappen te onderzoeken. Daarnaast werd deze tool toegepast om drie verschillende voorbeeldsystemen te onderzoeken en vergelijken. Al deze software is beschikbaar en eenvoudig bruikbaar voor andere gebruikers door de hulp een automatische installatie en configuratie van de benchmarking tool en de DBMS's. 

In dit hoofdstuk zullen eerst de uitdagingen besproken worden die overwonnen werden bij deze thesis. Dit wordt gevolgd met een overzicht voor potentieel verder onderzoek. Tenslotte wordt de thesis afgesloten met een samenvatting van de belangrijkste bijdragen. 

\section{Uitdagingen}
\paragraph{Handmatig opstellen van de DMBS's} De grootste uitdaging van de thesis was om de drie verschillende DBMS's handmatig te installeren en configureren tot een feilloos werkend systeem. Dit was een uitdaging omwille van verschillende redenen. 

Allereerst bestaan alle drie de systemen uit veelvoud van services en verschillende services gebruiken een andere configuratie methode. Bij HBase zijn er niet minder dan 5 verschillende services die elk geconfigureerd worden door middel van bestanden. Bij MongoDB verloopt de configuratie op zijn beurt via de terminal. 

Daarnaast zijn deze systemen nog volop in ontwikkeling, hierdoor is de documentatie vaak niet al te uitgebreid en zijn de foutmeldingen vaag. Dit was onder andere het geval bij Pgpool-II waarbij er enkel documentatie was voor Debian, maar de testinfrastructuur werkt met Fedora. Onder andere het gebruik van de beveiligingsmodule SELinux heeft de correcte werking van het herstel van Pgpool-II lange tijd gehinderd. 

\paragraph{Automatische installatie en configuratie van DBMS's} Als een systeem manueel kan opgezet worden, betekent dit niet dat er een onmiddellijke vertaling is naar het automatisch opstellen met behulp van IMP, hiervoor zijn er twee redenen. 

Allereerst kan het zijn dat een lijn in de terminal niet hetzelfde effect heeft dan wanneer deze in een bashscript wordt uitgevoerd. Het commando kan afhankelijk zijn van de huidige situatie van het DBMS. Bij MongoDB was het nodig om eerst de huidige configuratie te weten van de cluster voor het toevoegen of verwijderen van servers of replicaset's. 

Daarnaast kon IMP op het moment van de ontwikkeling nog geen afhankelijkheden aan tussen verschillende servers. Onder andere in MongoDB zorgde dit voor uitdagingen. Een replicaset kan bijvoorbeeld maar geïnitialiseerd worden wanneer alle servers online zijn. Met behulp van de thesis van Harm De Weirdt\cite{thesisHarm} is dit nu wel mogelijk in IMP. Als zijn methode toegepast wordt, zou de uitrol eenvoudiger kunnen verlopen.  

Hoewel de automatisatie de nodige tijd en moeite heeft gekost, heeft dit zijn plaats in deze thesis. Allereerst is het voor andere gebruikers eenvoudiger om de systemen op te zetten en de testen uit te voeren, dit was ook het geval voor mijzelf. Tijdens de ontwikkeling van de benchmarking tool was het af en toe nodig om al de servers te resetten. Het opnieuw opzetten van de infrastructuur ging veel vlotter, ook kon er eenvoudiger geëxperimenteerd met verschillende configuraties. 

\paragraph{Uitvoeren van de benchmarking tool} Een laatste uitdaging was het ontwikkelen van de benchmarking tool en de configuratie van de testen .De uitdaging hierbij zat hem in de tijd die nodig was om de testen op punt te stellen. Over de configuratieparameters is verschillende keren geïtereerd en elke iteratie kost veel tijd. Deze iteraties waren nodig bij het veranderen van de infrastructuur of de configuratie. Beiden kunnen als gevolg hebben dat het nieuwe systeem sneller of trager is. In de uiteindelijke configuratie duurt het uitvoeren van een enkele kalibratietest ongeveer 15 minuten, bij een consistentietest is dit ongeveer 10 minuten, bij een beschikbaarheidstest loopt dit op tot 20 minuten. 

\section{Verder werk}
In deze thesistekst zijn de eerste resultaten en conclusies naar beschikbaarheid en consistentie getrokken voor drie verschillende DBMS's. Een uitbreiding van het aantal geteste systemen zorgt er allereerst voor dat meer vergelijkend materiaal is maar daarnaast kunnen ook categorieën gevormd worden zoals bij het datamodel. 

Daarnaast kunnen de gebruikte testparameters ook aangepast worden om bepaalde assumpties te verifiëren of mathematische verbanden te zoeken. In de uitgevoerde testen hadden al de verschillende servers een ping tijd rond de 0.4ms, maar wat is bijvoorbeeld de invloed van deze parameter in de testen, hetzelfde geldt voor het aantal instanties van het DBMS en de belasting op de systemen (verkleint of vergroot het inconsistentie interval bij een hogere belasting?). 

Daarnaast kunnen ook de testmethode aangepast worden zoals het fysiek scheiden van de lezers en schrijven bij de consistentietest, wat een mogelijke invloed kan hebben op de resultaten. De beschikbaarheidstesten kunnen ook getest worden met verschillende fysieke gebruikers en onderzocht worden of deze hetzelfde gedrag hebben. 

Als laatste mogelijke uitbreiding, kunnen beide testen gecombineerd worden: verdwijnt er data als een instantie crasht en dit zowel vanuit het perspectief van de schrijver als de lezen. In MongoDB zou het mogelijk kunnen zijn dat een schrijfbewerking nog niet gerepliceerd was naar een secondary maar al wel gelezen was op de primary. Komt dit voor of zijn er mechanismen die dit voorkomen?  

\section{Evaluatie van de doelstellingen en bijdragen}
Deze thesis heeft met behulp van drie doelstellingen de kloof tussen de benodigde en beschikbare informatie kleiner gemaakt in relatie met de consistentie en beschikbaarheid van een DBMS. De verschillende doelstellingen en hun bijdrage zullen in deze sectie overlopen worden. 

\paragraph{Ontwikkelen van een benchmarking tool} In hoofdstuk \ref{sec:methodiekvantesten} is de algemene testmethode beschreven om de beschikbaarheid en consistentie van DBMS's te onderzoeken. Dit gebeurt door middel van verschillende stappen die bestaan uit het opstellen van de infrastructuur, uitvoeren van de testen en het analyseren van de resultaten. Hoofdstuk \ref{sec:implementatie} bespreekt hoe de verschillende stappen in de praktijk worden geïmplementeerd. De benchmarking tool is een uitbreiding van YCSB\cite{cooper2010benchmarking} met (1) ondersteuning voor het uitvoeren van instructies op gegeven tijdstippen en (2) een implementatie om leesbewerkingen uit te voeren tijdens en onmiddellijk na het schrijven van data. \\
De eerste uitbreiding is gebruikt voor de beschikbaarheidstesten, de tweede voor de consistentietesten. Deze benchmarking tool biedt basistesten aan die conclusies mogelijk maken. Zoals vermeldt in het verder werk kan deze testmethode verder uitgebreid worden. 

\paragraph{Analyseren van verschillende DBMS's} In hoofdstuk \ref{sec:observaties} zijn de observaties van drie verschillende DBMS's aan bod gekomen. Alle systemen zijn getest met behulp van de beschikbaarheidstesten, HBase en MongoDB zijn ook getest met de consistentietesten. In hoofdstuk \ref{sec:analyse} zijn de resultaten bestudeerd en de verschillen tussen de systemen besproken. \\
Uit de beschikbaarheidstesten blijkt dat de gecentraliseerde aanpak van Pgpool-II keer op keer dezelfde reactie geeft. De reacties van HBase en MongoDB zijn verschillend tussen verschillende uitvoeringen van dezelfde test. Beide systemen ondersteunen, in tegenstelling tot Pgpool-II, automatisch herstel van een node in het gedistribueerde opslag systeem. \\
Bij de consistentietesten is er een verschil hoe gelijktijdige bewerkingen worden uitgevoerd in MongoDB en HBase. Bij HBase wordt de schrijflock pas vrijgegeven na het volledig voltooien van de schrijfbewerking, hierna kan de leesbewerking uitgevoerd worden. In MongoDB wordt de schrijflock al vrijgegeven voor het volledig voltooien van de bewerking, met als gevolg dat leesacties de nieuwe data al lezen vooraleer een schrijfactie volledig voltooid is. \\
Bepaalde reacties van de systemen kunnen nog niet verklaard worden, maar met meer onderzoek is het mogelijk dat de reden achterhaald zou kunnen worden. Maar voor toekomstige gebruikers van deze DBMS's is er nu een overzicht wat de eigenschappen en het gedrag is bij het uitvallen van een service, node in het gedistribueerde opslag systeem of netwerk verbinding en hoe gelijktijdige lees- en schrijfbewerkingen afgehandeld worden. 

\paragraph{Eenvoudig herhalen en uitbreiden van de testen} Om de testen eenvoudig te kunnen herhalen, is de volledige testinfrastructuur op te stellen met behulp van IMP. Er is geen kennis nodig van de database systemen of de testsoftware, enkel de installatie van IMP met de nodige modules is nodig, gevolgd door het opstellen van de gewenste staat in een configuratie bestand en uiteindelijk de uitrol d.m.v. IMP. \\
De testen kunnen uitgebreid worden naar andere DBMS's, dit gebeurt in eerste instantie door de ondersteuning in YCSB te controleren of te implementeren, er is al standaard ondersteuning voor vele DBMS's. Daarna dienen de testen geconfigureerd worden specifiek voor deze database met behulp van de kalibratie. Daarna kunnen de beschikbaarheids- en consistentietesten voor dit nieuw systeem uitgevoerd worden.  