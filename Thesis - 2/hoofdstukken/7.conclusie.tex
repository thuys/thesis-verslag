\chapter{Conclusie}\label{sec:conclusie}
Deze thesis heeft de kloof verkleint tussen de informatie die nodig en beschikbaar is bij het selecteren van een DBMS. Dit is gebeurd door het ontwikkelen een nieuwe benchmarking tool om consistentie- en beschikbaarheidseigenschappen te onderzoeken. Daarnaast werd deze tool toegepast om drie verschillende voorbeeldsystemen te onderzoeken en vergelijken. Al deze software is beschikbaar een eenvoudig bruikbaar voor andere gebruikers door de hulp een automatische installatie en configuratie van de benchmarking tool en de DBMS's. 

In dit hoofdstuk zullen eerst de uitdagingen besproken worden die overwonnen werden bij deze thesis. Dit wordt gevolgd met een overzicht voor potentieel verder onderzoek. Tenslotte wordt de thesis afgesloten met een samenvatting van de belangrijkste bijdragen. 

\section{Uitdagingen}
\paragraph{Handmatig opstellen van de DMBS's} De grootste uitdaging van de thesis was de drie verschillende DBMS's eerste handmatig te installeren en configureren tot een feilloos werkend systeem. Dit was een uitdaging omwille van verschillende redenen. 

Allereerst bestaan alle drie de systemen uit veelvoud van services en verschillende services gebruiken een andere configuratie methode. Bij HBase zijn er niet minder dan 5 verschillende services die elk geconfigureerd worden door middel van bestanden. Bij MongoDB verloopt de configuratie op zijn beurt via de terminal. 

Daarnaast is zijn deze systemen nog volop in ontwikkeling, hierdoor is de documentatie vaak niet al te uitgebreid en zijn de foutmeldingen vaag. Dit was onder andere het geval bij Pgpool-II waarbij er enkel documentatie was voor Debian, maar de infrastructuur draaide op Fedora. Onder andere het gebruik van de beveiligingsmodule SELinux heeft de werking van het herstel van Pgpool-II lange tijd geblokkeerd. 

\paragraph{Automatische installatie en configuratie van DBMS's} Als een systeem manueel kan opgezet worden, betekent dit niet dat er een onmiddellijke vertaling is naar het automatisch opstellen met behulp van IMP, hiervoor zijn er twee redenen. 

Allereerst kan het zijn dat een lijn in de terminal niet hetzelfde effect heeft dan wanneer deze in een bashscript wordt uitgevoerd of het commando is afhankelijk van de huidige situatie van het DBMS. Bij MongoDB was het nodig om eerst de huidige configuratie te weten van de cluster voor het toevoegen of verwijderen van servers of replicaset's. 

Daarnaast kon IMP op het moment van de ontwikkeling nog geen afhankelijkheden aan tussen verschillende servers. Onder andere in MongoDB zorgde dit voor uitdagingen aangezien bijvoorbeeld een replicaset maar geïnitialiseerd kan worden wanneer alle servers online zijn. Met behulp van de thesis van Harm De Weirdt\cite{thesisHarm} is dit nu wel mogelijk in IMP en zou de uitrol eenvoudiger verlopen als zijn methode toegepast wordt.  

Hoewel de automatisatie de nodige tijd en moeite heeft gekost, heeft dit zijn plaats in deze thesis. Allereerst is het voor andere gebruikers eenvoudiger om de systemen op te zetten en de testen uit te voeren, dit is ook het geval voor mijzelf. Tijdens de ontwikkeling van de benchmarking tool was het af en toe nodig om al de servers te resetten. Het opnieuw opzetten van de infrastructuur ging veel vlotter, ook kon er eenvoudiger geëxperimenteerd met verschillende configuraties. 

\paragraph{Uitvoeren van de benchmarking tool} Een laatste uitdaging was het ontwikkelen van de benchmarking tool en de configuratie van de testen, de uitdaging hierbij zat hem in de tijd die nodig was om de testen op punt te stellen. Over de configuratieparameters is verschillende keren geïtereerd, maar elke iteratie kost veel tijd. Dit kan onder andere gebeuren bij het veranderen van de infrastructuur of de configuratie, beiden kunnen als gevolg hebben dat het nieuwe systeem sneller of trager is. In de uiteindelijke configuratie duurt het uitvoeren van een enkele calibratietest ongeveer 15 minuten, bij een consistentietest is dit ongeveer 10 minuten, bij een beschikbaarheidstest loopt dit op tot 20 minuten. 

\section{Verder werk}
In deze thesistekst zijn de eerste resultaten en conclusies naar beschikbaarheid en consistentie getrokken voor drie verschillende DBMS's. Een uitbreiding van het aantal geteste systemen zorgt allereerst ervoor dat meer vergelijkend materiaal is maar daarnaast kunnen ook categorieën gevormd worden zoals bij het datamodel. 

Daarnaast kunnen de gebruikte testparameters ook aangepast worden om bepaalde assumpties te verifiëren of mathematische verbanden te zoeken. In de uitgevoerde testen hadden al de verschillende servers een ping tijd rond de 0.5ms, maar wat is bijvoorbeeld de invloed van deze parameter in de testen, hetzelfde geldt voor het aantal instanties van het DBMS en de belasting op de systemen (verkleint of vergroot het inconsistentie interval bij een hogere belasting?). 

Daarnaast kunnen ook de testmethode aangepast worden zoals bij de consistentietest de lezers en schrijver fysiek scheiden, dit kan mogelijk een invloed hebben. De beschikbaarheidstesten kunnen ook getest worden met verschillende fysieke gebruikers en te onderzoeken of deze hetzelfde gedrag meten. Het zou kunnen dat in bepaalde systemen het mogelijk is om op verschillende netwerk partities tegelijk te lezen en schrijven waardoor er data verloren kan gaan. 

Als laatste mogelijke uitbreiding, kunnen beide testen gecombineerd worden: verdwijnt er data als een instantie crasht en dit zowel vanuit het perspectief van de schrijver als de lezen. In MongoDB zou het mogelijk kunnen zijn dat een schrijfbewerking nog niet gerepliceerd was naar een secondary maar al wel gelezen was op de primary. Komt dit voor of zijn er mechanismen die dit voorkomen?  

\section{Evaluatie van de doelstellingen en bijdragen}
Deze thesis heeft met behulp van drie doelstellingen de kloof tussen de benodigde en beschikbare informatie kleiner gemaakt in relatie met de consistentie en beschikbaarheid van een DBMS. De verschillende doelstellingen zullen in deze sectie overlopen worden en hoe deze één voor één bijdragen tot het verkleinen van de kloof. 

\paragraph{Ontwikkelen van een benchmarking tool} In hoofdstuk \ref{sec:methodiekvantesten} is de algemene testmethode beschreven om de beschikbaarheid en consistentie van DBMS's te onderzoeken. Dit gebeurt door middel van verschillende stappen die bestaan uit het opstellen van de infrastructuur, uitvoeren van de testen en het analyseren van de resultaten. Hoofdstuk \ref{sec:implementatie} bespreekt hoe de verschillende stappen in de praktijk worden geïmplementeerd. De benchmarking tool is een uitbreiding van YCSB\cite{cooper2010benchmarking} met (1) ondersteuning voor het uitvoeren van instructies op gegeven tijdstippen en (2) een implementatie om leesbewerkingen uit te voeren tijdens en onmiddellijk na het schrijven van data. \\
De eerste uitbreiding is gebruikt voor de beschikbaarheidstesten, de tweede voor de consistentietesten. Deze benchmarking tool biedt basistesten aan die conclusies mogelijk maken. Zoals vermeldt in het verder werk kan deze testmethode verder uitgebreid worden. 

\paragraph{Analyseren van verschillende DBMS's} In hoofdstuk \ref{sec:observaties} zijn de observaties van drie verschillende DBMS's aan bod gekomen. Alle systemen zijn getest met behulp van de beschikbaarheidstesten, HBase en MongoDB zijn ook getest met de consistentietesten. In hoofdstuk \ref{sec:analyse} zijn de resultaten bestudeerd en zijn verschillen tussen de systemen besproken. \\
Uit de beschikbaarheidstesten blijkt dat de gecentraliseerde aanpak van Pgpool-II keer op keer dezelfde reactie geeft. De reactie van HBase en MongoDB zijn verschillend tussen verschillende uitvoeringen van dezelfde test. De gedecentraliseerde aanpak biedt wel een betere robuustheid bij het uitvallen van een willekeurige server. \\
Bij de consistentietesten is er een verschil hoe gelijktijdige bewerkingen worden uitgevoerd in MongoDB en HBase. Bij HBase wordt de schrijflock pas vrijgegeven na het volledig voltooien van de schrijfbewerking, hierna kan de leesbewerking uitgevoerd worden. In MongoDB wordt de schrijflock al vrijgegeven voor het volledig voltooien van de bewerking, met als gevolg dat leesacties de nieuwe data al lezen vooraleer een schrijfactie volledig voltooid is. \\
Bepaalde reacties van de systemen kunnen nog niet verklaard worden, maar met meer onderzoek is het mogelijk dat de reden achterhaald zou kunnen worden. Maar voor toekomstige gebruikers van deze DBMS's is er nu een overzicht wat de eigenschappen en het gedrag is bij het uitvallen van een service, server of netwerk verbinding en hoe gelijktijdige lees- en schrijfbewerkingen afgehandeld worden. 

\paragraph{Eenvoudig herhalen en uitbreiden van de testen} Om de testen eenvoudig te kunnen herhalen, is de volledige testinfrastructuur op te stellen met behulp van IMP. Er is geen kennis nodig van de database systemen of de testsoftware, enkel de installatie van IMP met de nodige modules is nodig, gevolgd door een aanpassing aan het configuratie bestand en uiteindelijk de uitrol d.m.v. IMP. \\
De testen kunnen uitgebreid worden naar andere DBMS's, dit gebeurt in eerste instantie door de ondersteuning in YCSB te controleren of te implementeren, voor de vele DBMS's is dit al gebeurd. Daarna dient het script, de calibratie van het nieuwe systeem uitgevoerd te worden. 